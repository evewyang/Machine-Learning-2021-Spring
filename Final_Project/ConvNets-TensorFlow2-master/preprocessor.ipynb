{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "from PIL import Image as pil\n",
    "\n",
    "def to_lower(arr):\n",
    "    for i in range(0,len(arr)):\n",
    "        arr[i] = arr[i].lower()\n",
    "    return arr\n",
    "def label_to_num(label_list):\n",
    "    label_dict = {}\n",
    "    labels = np.unique(label_list)\n",
    "    for i in range (0, len(labels)):\n",
    "        label_dict[labels[i]] = i\n",
    "    for j in range (0, len(label_list)):\n",
    "        label_list[j] = label_dict[label_list[j]]\n",
    "    return label_dict, label_list\n",
    "# def convertImageToGray(image, cvtr):\n",
    "#     #convert RGB(3-channel)/RGBA(4-channel) pics to 2-channel greyscale\n",
    "#     gray = cvtr.cvtColor(image, cvtr.COLOR_BGR2GRAY)\n",
    "#     return gray\n",
    "# def convert_gray_to_color(image, cvtr):\n",
    "#     #Grayscale to RGB(3-channel)\n",
    "#     color = cvtr.cvtColor(image, cvtr.COLOR_GRAY2RGB)\n",
    "#     return color\n",
    "# def vectorize_matrix(mat):\n",
    "#     #sraighten the matrix into a column\n",
    "#     col_vector = np.reshape(mat, (len(mat)*len(mat[0]),1))\n",
    "#     return col_vector\n",
    "def attach(mat1,mat2):\n",
    "    mat2 = np.reshape(mat2,(1,len(mat2),len(mat2[0]),len(mat2[0][0])))\n",
    "    if (type(mat1) != np.ndarray):\n",
    "        mat1 = np.array(mat1)\n",
    "        mat1 = mat2\n",
    "    else:\n",
    "        mat1 = np.append(mat1, mat2, axis=0)\n",
    "    return mat1\n",
    "def resize_img(input_data, path_to_find, path_to_save, size = (32,32)):\n",
    "    for i in range(0, len(input_data)):\n",
    "        try:\n",
    "            file = pil.open(path_to_find + input_data[i])\n",
    "            file = file.resize(size)\n",
    "            file = file.convert(\"RGB\")\n",
    "            file = file.save(path_to_save + input_data[i])\n",
    "        except:\n",
    "            print(\"Image %s cannot be openned.\"%(input_data[i]))\n",
    "def get_pic_matrix(input_data, filepath):\n",
    "    #initialize a new array to hold vectorized pics\n",
    "    input_pics = []\n",
    "    #two new list to record imgs' idx where they fail to open or process\n",
    "    idx_exception = []\n",
    "    #transfrom the corresponding pictures into matrices, then vectors.\n",
    "    #for train_pics in X_train:\n",
    "    for i in range(0, len(input_data)):\n",
    "        try:\n",
    "            image = img.imread(filepath + input_data[i])\n",
    "#             if (len(image.shape) == 2):\n",
    "#                 #so convert Grayscale to RGB\n",
    "#                 image = convert_gray_to_color(image, img)\n",
    "#             if (len(image.shape) < 2):\n",
    "#                 #record \"throw-away\" pics' idx\n",
    "#                 idx_exception.append(i)\n",
    "#                 continue\n",
    "        except:\n",
    "            #record \"throw-away\" pics' idx\n",
    "            idx_exception.append(i)\n",
    "            continue\n",
    "        input_pics = attach(input_pics,image)\n",
    "        #img_vector, explained_variane = get_pc(image,pca)\n",
    "    return input_pics, idx_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "my_data = pd.read_csv('../facial_expressions-master/data/legend.csv').values\n",
    "X_data = my_data[: , 1]\n",
    "y_data = my_data[: , 2]\n",
    "y_data = to_lower(y_data)\n",
    "#y_data into int labels\n",
    "y_dict, y_data = label_to_num(y_data)\n",
    "\n",
    "# Spiliting Data 67-33 ratio as said by sir\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image facial-expressions_2868588k.jpg cannot be openned.\n"
     ]
    }
   ],
   "source": [
    "#to save resized images\n",
    "my_path1 = \"../facial_expressions-master/images/\"\n",
    "my_path2 = \"../facial_expressions-master/resized_images/\"\n",
    "resize_img(X_data, my_path1, my_path2,(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "X_train_pics, idx_train_exception = get_pic_matrix(X_train, my_path2)\n",
    "print(\"yes\")\n",
    "X_test_pics, idx_test_exception = get_pic_matrix(X_test, my_path2)\n",
    "#convert X_data to ndarray\n",
    "# X_train_pics = X_train_pics.reshape((len(X_train_pics),len(X_train_pics[0]),len(X_train_pics[0][0]),1))\n",
    "# X_test_pics = X_test_pics.reshape((len(X_test_pics),len(X_test_pics[0]),len(X_test_pics[0][0]),1))\n",
    "#throw away unprocessable imgs' idx for y data\n",
    "y_train = np.delete(y_train,idx_train_exception,axis = 0)\n",
    "y_test = np.delete(y_test,idx_test_exception,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.uint8)\n",
    "y_test = y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
